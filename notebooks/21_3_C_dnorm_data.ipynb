{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "inputPath = './data/records_samples/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataframe with records\n",
    "Create records_samples folder in data if not there\n",
    "Place records.pkl and samples.pkl in folder from shared folder in google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_record = pd.read_pickle(os.path.join(inputPath,'records.pkl'))\n",
    "df_record.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DNorm input data\n",
    "First part of notebook: we will create the input data for dnorm \n",
    "From a pandas dataframe that contains the records (records.pkl)\n",
    "Input whether you want all records or a certain number of records \n",
    " - For all records: all_rows=1\n",
    " - For fixed number, all_rows=0 and n_rows=[number of rows you want]\n",
    " \n",
    "This will output DNorm input data to data/DNorm_input.txt\n",
    " \n",
    "To run DNorm you then place this into the DNorm folder and run code \n",
    "For DNorm instructions download java app here: ncbi.nlm.nih.gov/research/bionlp/Tools/dnorm and look at readme text file inside folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = 1\n",
    "n_rows = 1000\n",
    "\n",
    "\n",
    "if all_rows==1:\n",
    "    n_rows = len(df_record)\n",
    "\n",
    "rec4input = df_record.loc[:n_rows,:]\n",
    "\n",
    "outF = open(os.path.join(inputPath, 'dnorm_input.txt'), \"w\")\n",
    "# build list of strings\n",
    "rec4input = rec4input.reset_index()\n",
    "for i in range(len(rec4input)):\n",
    "    Id = rec4input.loc[i,:].Id\n",
    "    title = rec4input.loc[i,:].title\n",
    "    summary = rec4input.loc[i,:].summary\n",
    "    outF.write(Id)\n",
    "    outF.write('\\t')\n",
    "    outF.write(title +'. '+ summary)\n",
    "    outF.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn DNorm output into pandas df\n",
    " - After running DNorm, take text output file and paste into output_data_path folder\n",
    " - Turn into dataframe and save to output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_path = './data/DNorm/'\n",
    "\n",
    "if os.path.isdir(output_data_path)!=1:\n",
    "    os.mkdir(output_data_path)\n",
    "\n",
    "output_file_path = os.path.join(output_data_path, 'record_tags.txt')\n",
    "\n",
    "with open(output_file_path,'r') as f:\n",
    "    data = f.read().splitlines()\n",
    "    \n",
    "table = [d.split('\\t') for d in data]\n",
    "headers = ['Id', 'start', 'end', 'disease_tag', 'ONTid']\n",
    "df = pd.DataFrame(table, columns=headers)\n",
    "\n",
    "s = df.ONTid.str.split(':')\n",
    "df_aux = pd.DataFrame.from_items(zip(s.index, s.values)).T\n",
    "df_aux.columns = ['ont', 'unique_id']\n",
    "df['ont'] = df_aux['ont']\n",
    "df['unique_id'] = df_aux['unique_id']\n",
    "df = df.drop('ONTid', axis = 1)\n",
    "\n",
    "df.to_pickle(os.path.join(output_data_path,'disease_tags.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
