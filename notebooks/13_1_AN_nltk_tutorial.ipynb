{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Installing and Using NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download() # download all packages/collections in nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. Sampath, how are you doing today?', 'The weather is great and NLTK is interesting.', 'It is snowing here and really, it is pretty cold.', 'Though at -5 degrees, actually quite warmer than usual!', 'Okay, bye now.', 'ttyl.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "example_text = \"Hello Mr. Sampath, how are you doing today? The weather is great and NLTK is interesting. It is snowing here and really, it is pretty cold. Though at -5 degrees, actually quite warmer than usual! Okay, bye now. ttyl.\"\n",
    "print(sent_tokenize(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'Sampath', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', 'and', 'NLTK', 'is', 'interesting', '.', 'It', 'is', 'snowing', 'here', 'and', 'really', ',', 'it', 'is', 'pretty', 'cold', '.', 'Though', 'at', '-5', 'degrees', ',', 'actually', 'quite', 'warmer', 'than', 'usual', '!', 'Okay', ',', 'bye', 'now', '.', 'ttyl', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(example_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Stop Words\n",
    "Stop words are words which are filtered out before or after processing of natural language data. Stop words usually refers to the most common words in a language (Note: there is no single universal list of stop words used by all natural language processing tools, and indeed not all tools even use such a list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'example', 'sentence', 'showing', 'stop', 'word', 'filtration', '.', 'Hopefully', ',', 'work', '!', 'Or', ',', '?', 'Wont', '?', '?', 'Lets', 'find', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "example_sentence = \"This is an example sentence showing stop word filtration. Hopefully, this will work! Or, will it? Wont it?? Lets find out!!\"\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "words = word_tokenize(example_sentence)\n",
    "filtered_sentence = []\n",
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "# The above for loop as a one-liner\n",
    "# filtered_sentence = [w for w in words if w not in stop_words]\n",
    "\n",
    "print(filtered_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
