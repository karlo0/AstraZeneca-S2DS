{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>Fetch and Process Data</h1>\n",
    "\n",
    "Follow the instructions and execute the script to fetch and process records and samples from the geo database and to generate a dataframe with all mesh ids and their corresponding mesh headings and main categories \n",
    "<h2>Input</h2>\n",
    "<h3>Search query</h3>\n",
    "<h4>String input</h4>\n",
    "First, input search terms that shall be contained in the desired geo DataSets. Please look at\n",
    "(https://www.ncbi.nlm.nih.gov/geo/info/qqtutorial.html)\n",
    "for all possibilities. To construct a complex query, specify the search terms, their fields, and the Boolean operations to perform on the terms using the following syntax:\n",
    "\n",
    "`term [field] OPERATOR term [field]`\n",
    "\n",
    "where \n",
    "- `term` is the search term, e.g. GSE for geo database series\n",
    "- `[field]` is the search field, e.g. [ETYP] to specify the record type (GDS - DataSet, GSE - Series, GPL - Platform), [Organism] to specify the subject of studies (Homo Sapies - humans, see more below)\n",
    "- `OPERATOR` is the Boolean operator ('AND', 'OR', 'NOT') which must be capitalized.\n",
    "\n",
    "When you press enter without giving a string expression for the query, the following standard query is performed,\n",
    "\n",
    "`GSE[ETYP] AND Homo[Organism]`\n",
    "\n",
    "which fetches all geo series with studies on humans. The following list shows the most used terms for [field]=[Organism]:\n",
    "1. Homo sapiens (human)\n",
    "2. Mus musculus (house mouse)\n",
    "3. Rattus norvegicus (brown rat)\n",
    "4. Macaca mulatta (rhesus macaque)\n",
    "5. Drosophila melanogaster (common fruit fly)\n",
    "\n",
    "<h4>Number of studies to be retrieved</h4>\n",
    "Next, specify the number of geo database entries, N>0, that you wish to extract. If you input N<=0 or nothing, all found geo database entries for the search query will be fetched\n",
    "\n",
    "<h2>Final Output</h2>\n",
    "This script fetches the data and processes it and outputs two pandas dataframes:\n",
    "- BASE/data/final/geo.pkl\n",
    "- BASE/data/final/mesh.pkl\n",
    "where BASE is the BASE folder of the entire repository.\n",
    "geo.pkl: contains all geo datasets ids together with their dates and number of samples included. In further columns the corresponding mesh ids, the category of the mesh ids and the method of obtaining the mesh ids are specified (a) DNORM when via the tagging tool DNORM b) PMID when following the id of pubmed publications that are already tagged with mesh ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Fetching raw data ##\n",
      "\n",
      "Input search terms that shall be contained in the desired geo DataSets.\n",
      "Please look at\n",
      "\n",
      "https://www.ncbi.nlm.nih.gov/geo/info/qqtutorial.html\n",
      "\n",
      "for all possibilities. To construct a complex query, specify the search terms,\n",
      "their fields, and the Boolean operations to perform on the terms using the following syntax:\n",
      "\n",
      "term [field] OPERATOR term [field]\n",
      "\n",
      "where term is the search term, field is the search field, and OPERATOR is the\n",
      "Boolean operator ('AND', 'OR', 'NOT') which must be capitalized.\n",
      "When you press enter without giving a string expression for the query, the following standard query is performed,\n",
      "\n",
      "GSE[ETYP] AND Homo[Organism]\n",
      "\n",
      "which retrieves all geo series with studies performed for/on humans.\n",
      "\n",
      "The following list shows the most used terms for field=Organism:\n",
      "1. Homo sapiens (human)\n",
      "2. Mus musculus (house mouse)\n",
      "3. Rattus norvegicus (brown rat)\n",
      "4. Macaca mulatta (rhesus macaque)\n",
      "5. Drosophila melanogaster (common fruit fly)\n",
      "\n",
      "Input: GSE[ETYP] AND Mus musculus[Organism]\n",
      "\n",
      "A total of 32900 geo datasets that are compatible with the search query have been found.\n",
      "\n",
      "Specify the number of geo database entries, N>0, that you wish to extract.\n",
      "If you input N<=0 or nothing, all found geo database entries for the search query will be fetched\n",
      "N = 100\n",
      "Number of geo datasets to be fetched: 100\n",
      "\n",
      "\n",
      "Going to download record 1 to 100\n",
      "\n",
      "## parse data into dataframes ##\n",
      "\n",
      "Parsing  /home/karlo/share_drive/Documents/S2DS_Bootcamp/Github/test_house_mouse/data/raw/geo_data/all_gse_series_raw_part0.xml\n",
      "Sample iteration:\n",
      "0\n",
      "Saving samples to  /home/karlo/share_drive/Documents/S2DS_Bootcamp/Github/test_house_mouse/data/interim/records_samples/samples.pkl\n",
      "\n",
      "Saving records to  /home/karlo/share_drive/Documents/S2DS_Bootcamp/Github/test_house_mouse/data/interim/records_samples/records.pkl\n",
      "\n",
      "Done.\n",
      "\n",
      "## download mesh ids and its corresponding mesh headings and put it into the BASE/data/final/mesh.pkl dataframe ##\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py:635: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## obtain mesh ids for geo series by following pubmed puplications ##\n",
      "\n",
      "start load records database\n",
      "done\n",
      "Going to download mesh-ui numbers of the pubmed puplications 1 to 8\n",
      "\n",
      "## obtain mesh ids for geo series by calling the DNORM program via the RESTFUL API ##\n",
      "\n",
      "\n",
      "## \t Note: This can take up to a couple of hours for many geo series ##\n",
      "\n",
      "This script uses NCBI restful API https://www.ncbi.nlm.nih.gov/research/bionlp/APIs/\n",
      "First we request tags from records in batches (e.g. n=1000), then we save the tags.      \n",
      "~45000 summaries should take ~30 minutes to tag with one tagger.\n",
      "\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "| Tagging with DNorm\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "There are 87 records.\n",
      "\n",
      "Requesting tags for records from 0 to 87\n",
      "Thanks for your submission. The session number is : 5415-8556-7393-9193\n",
      "The request is received and processing....\n",
      "\n",
      "\n",
      "Attempt to save this URL to file (Do not click): https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/RESTful/tmTool.cgi/5415-8556-7393-9193/Receive/\n",
      "Time elapsed since tagging began is  5.1\n",
      "code=501\n",
      "Time elapsed since tagging began is  10.55\n",
      "code=501\n",
      "Time elapsed since tagging began is  16.1\n",
      "code=501\n",
      "Time elapsed since tagging began is  21.55\n",
      "code=501\n",
      "Time elapsed since tagging began is  27.1\n",
      "code=501\n",
      "Time elapsed since tagging began is  32.66\n",
      "code=501\n",
      "Time elapsed since tagging began is  38.09\n",
      "code=501\n",
      "Time elapsed since tagging began is  43.58\n",
      "code=501\n",
      "Time elapsed since tagging began is  49.18\n",
      "code=200\n",
      "\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "| Tagging with tmChem\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "There are 87 records.\n",
      "\n",
      "Requesting tags for records from 0 to 87\n",
      "Thanks for your submission. The session number is : 5072-3792-8187-3649\n",
      "The request is received and processing....\n",
      "\n",
      "\n",
      "Attempt to save this URL to file (Do not click): https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/RESTful/tmTool.cgi/5072-3792-8187-3649/Receive/\n",
      "Time elapsed since tagging began is  4.95\n",
      "code=501\n",
      "Time elapsed since tagging began is  10.48\n",
      "code=501\n",
      "Time elapsed since tagging began is  15.92\n",
      "code=501\n",
      "Time elapsed since tagging began is  21.4\n",
      "code=501\n",
      "Time elapsed since tagging began is  26.96\n",
      "code=501\n",
      "Time elapsed since tagging began is  32.41\n",
      "code=501\n",
      "Time elapsed since tagging began is  37.89\n",
      "code=501\n",
      "Time elapsed since tagging began is  43.37\n",
      "code=501\n",
      "Time elapsed since tagging began is  48.84\n",
      "code=501\n",
      "Time elapsed since tagging began is  54.34\n",
      "code=501\n",
      "Time elapsed since tagging began is  59.85\n",
      "code=501\n",
      "Time elapsed since tagging began is  65.3\n",
      "code=501\n",
      "Time elapsed since tagging began is  70.82\n",
      "code=501\n",
      "Time elapsed since tagging began is  76.26\n",
      "code=501\n",
      "Time elapsed since tagging began is  81.73\n",
      "code=501\n",
      "Time elapsed since tagging began is  87.19\n",
      "code=501\n",
      "Time elapsed since tagging began is  92.75\n",
      "code=501\n",
      "Time elapsed since tagging began is  98.2\n",
      "code=501\n",
      "Time elapsed since tagging began is  103.74\n",
      "code=200\n",
      "\n",
      "## unify both dataframes that contain the geo series ids together with the obtained mesh ids from the 2 different methods and finalize the dataframe ##\n",
      "\n",
      "start load raw geo dataframe\n",
      "done\n",
      "start load mesh df with meshid-mesh headings-mesh tree number rows\n",
      "done\n",
      "start load df with mesh data obtained via DNORM\n",
      "done\n",
      "start load df with mesh data obtained via following pubmed publications\n",
      "done\n",
      "store geo df\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "## Set paths                                                                                                                                                                                                                              \n",
    "# cdir = dir of this script\n",
    "cdir = os.path.abspath('')                                                                                                                                                                                      \n",
    "# basedir = root dir of the repository                                                                                                                                                                                                    \n",
    "basedir = os.path.dirname(cdir)\n",
    "os.chdir(basedir+'/src/data/')\n",
    "#execute scripts\n",
    "%run fetch_store_geo_series.py\n",
    "%run parse_raw_data.py\n",
    "%run id_name_tree_generation.py\n",
    "%run meshtags_pmid.py\n",
    "%run meshtags_dnorm_restful_api.py\n",
    "%run unify_finalize_geo_to_mesh_dfs.py\n",
    "# change dir back to the original one\n",
    "os.chdir(cdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
